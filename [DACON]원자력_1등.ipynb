{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dacon 15회 원자력발전소 상태 판단 경진대회\n",
    "### 밍둥이\n",
    "### 2020년 2월 16일\n",
    "### 1. 라이브러리 및 데이터\n",
    "### Library & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm\n",
    "\n",
    "import multiprocessing # 여러 개의 일꾼 (cpu)들에게 작업을 분산시키는 역할\n",
    "from multiprocessing import Pool \n",
    "from functools import partial # 함수가 받는 인자들 중 몇개를 고정 시켜서 새롭게 파생된 함수를 형성하는 역할\n",
    "from data_loader_v2 import data_loader_v2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "path= \"C:/dacon/nuclear/\"\n",
    "train_folder = path+\"train/\"\n",
    "test_folder = path+\"test/\"\n",
    "train_label_path = path+\"train_label.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 전처리\n",
    "### Data Cleansing & Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = os.listdir(train_folder)\n",
    "test_list = os.listdir(test_folder)\n",
    "train_label = pd.read_csv(train_label_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 csv 파일의 상태_B로 변화는 시점이 같다라고 가정\n",
    "# 하지만, 개별 csv파일의 상태_B로 변화는 시점은 상이할 수 있음\n",
    "def data_loader_all_v2(func, files, folder='', train_label=None, event_time=10, nrows=60):   \n",
    "    func_fixed = partial(func, folder=folder, train_label=train_label, event_time=event_time, nrows=nrows)     \n",
    "    if __name__ == '__main__':\n",
    "        pool = Pool(processes=multiprocessing.cpu_count()) \n",
    "        df_list = list(pool.imap(func_fixed, files)) \n",
    "        pool.close()\n",
    "        pool.join()        \n",
    "    combined_df = pd.concat(df_list)    \n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_loader_all_v2(data_loader_v2, train_list, folder=train_folder, train_label=train_label, event_time=10, nrows=60)\n",
    "test = data_loader_all_v2(data_loader_v2, test_list, folder=test_folder, train_label=None, event_time=20, nrows=60)\n",
    "\n",
    "y = train['label']\n",
    "train.drop('label',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (41350, 5121)\n",
      "test shape : (28720, 5121)\n",
      "y shape : (41350,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape : {}\".format(train.shape))\n",
    "print(\"test shape : {}\".format(test.shape))\n",
    "print(\"y shape : {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0000</th>\n",
       "      <th>V0001</th>\n",
       "      <th>V0002</th>\n",
       "      <th>V0003</th>\n",
       "      <th>V0004</th>\n",
       "      <th>V0005</th>\n",
       "      <th>V0006</th>\n",
       "      <th>V0007</th>\n",
       "      <th>V0008</th>\n",
       "      <th>V0009</th>\n",
       "      <th>...</th>\n",
       "      <th>V5111</th>\n",
       "      <th>V5112</th>\n",
       "      <th>V5113</th>\n",
       "      <th>V5114</th>\n",
       "      <th>V5115</th>\n",
       "      <th>V5116</th>\n",
       "      <th>V5117</th>\n",
       "      <th>V5118</th>\n",
       "      <th>V5119</th>\n",
       "      <th>V5120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.474394</td>\n",
       "      <td>8.691177</td>\n",
       "      <td>8.714483</td>\n",
       "      <td>8.687399</td>\n",
       "      <td>8.721230</td>\n",
       "      <td>207.697895</td>\n",
       "      <td>165.865730</td>\n",
       "      <td>-6.018877e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002136</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.421620e-05</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.470463</td>\n",
       "      <td>8.736521</td>\n",
       "      <td>8.682769</td>\n",
       "      <td>8.717135</td>\n",
       "      <td>8.682402</td>\n",
       "      <td>192.665080</td>\n",
       "      <td>191.006871</td>\n",
       "      <td>-3.918758e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.114455e-06</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.465427</td>\n",
       "      <td>8.753559</td>\n",
       "      <td>8.663426</td>\n",
       "      <td>8.700049</td>\n",
       "      <td>8.734147</td>\n",
       "      <td>187.065171</td>\n",
       "      <td>192.700238</td>\n",
       "      <td>-1.799179e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.813291e-05</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.458532</td>\n",
       "      <td>8.715056</td>\n",
       "      <td>8.714854</td>\n",
       "      <td>8.717174</td>\n",
       "      <td>8.699257</td>\n",
       "      <td>188.500036</td>\n",
       "      <td>180.150567</td>\n",
       "      <td>-6.636971e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.745568e-07</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.475773</td>\n",
       "      <td>8.790241</td>\n",
       "      <td>8.735125</td>\n",
       "      <td>8.703167</td>\n",
       "      <td>8.721030</td>\n",
       "      <td>193.269046</td>\n",
       "      <td>195.984890</td>\n",
       "      <td>-6.379752e-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.437883e-06</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V0000     V0001     V0002     V0003     V0004       V0005       V0006  \\\n",
       "0  30.474394  8.691177  8.714483  8.687399  8.721230  207.697895  165.865730   \n",
       "0  30.470463  8.736521  8.682769  8.717135  8.682402  192.665080  191.006871   \n",
       "0  30.465427  8.753559  8.663426  8.700049  8.734147  187.065171  192.700238   \n",
       "0  30.458532  8.715056  8.714854  8.717174  8.699257  188.500036  180.150567   \n",
       "0  30.475773  8.790241  8.735125  8.703167  8.721030  193.269046  195.984890   \n",
       "\n",
       "          V0007  V0008     V0009  ...  V5111  V5112  V5113  V5114  V5115  \\\n",
       "0 -6.018877e-19    0.0 -0.002136  ...    1.0    1.0    1.0    1.0   60.0   \n",
       "0 -3.918758e-19    0.0  0.001710  ...    1.0    1.0    1.0    1.0   60.0   \n",
       "0 -1.799179e-19    0.0  0.000493  ...    1.0    1.0    1.0    1.0   60.0   \n",
       "0 -6.636971e-19    0.0  0.000318  ...    1.0    1.0    1.0    1.0   60.0   \n",
       "0 -6.379752e-20    0.0 -0.000091  ...    1.0    1.0    1.0    1.0   60.0   \n",
       "\n",
       "   V5116  V5117         V5118  V5119  V5120  \n",
       "0    0.0    0.0  1.421620e-05   85.4    0.0  \n",
       "0    0.0    0.0 -6.114455e-06   85.4    0.0  \n",
       "0    0.0    0.0 -1.813291e-05   85.4    0.0  \n",
       "0    0.0    0.0 -5.745568e-07   85.4    0.0  \n",
       "0    0.0    0.0  8.437883e-06   85.4    0.0  \n",
       "\n",
       "[5 rows x 5121 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0000</th>\n",
       "      <th>V0001</th>\n",
       "      <th>V0002</th>\n",
       "      <th>V0003</th>\n",
       "      <th>V0004</th>\n",
       "      <th>V0005</th>\n",
       "      <th>V0006</th>\n",
       "      <th>V0007</th>\n",
       "      <th>V0008</th>\n",
       "      <th>V0009</th>\n",
       "      <th>...</th>\n",
       "      <th>V5111</th>\n",
       "      <th>V5112</th>\n",
       "      <th>V5113</th>\n",
       "      <th>V5114</th>\n",
       "      <th>V5115</th>\n",
       "      <th>V5116</th>\n",
       "      <th>V5117</th>\n",
       "      <th>V5118</th>\n",
       "      <th>V5119</th>\n",
       "      <th>V5120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>30.466746</td>\n",
       "      <td>8.766340</td>\n",
       "      <td>8.688246</td>\n",
       "      <td>8.725044</td>\n",
       "      <td>8.691887</td>\n",
       "      <td>164.129395</td>\n",
       "      <td>192.704677</td>\n",
       "      <td>4.585456e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>30.461517</td>\n",
       "      <td>8.615086</td>\n",
       "      <td>8.707004</td>\n",
       "      <td>8.672025</td>\n",
       "      <td>8.726185</td>\n",
       "      <td>200.608939</td>\n",
       "      <td>180.603857</td>\n",
       "      <td>6.708315e-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>30.462584</td>\n",
       "      <td>8.734225</td>\n",
       "      <td>8.711064</td>\n",
       "      <td>8.700966</td>\n",
       "      <td>8.723912</td>\n",
       "      <td>180.847520</td>\n",
       "      <td>170.057365</td>\n",
       "      <td>2.970597e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001302</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>30.486272</td>\n",
       "      <td>8.547549</td>\n",
       "      <td>8.705390</td>\n",
       "      <td>8.677280</td>\n",
       "      <td>8.684212</td>\n",
       "      <td>201.880368</td>\n",
       "      <td>194.272476</td>\n",
       "      <td>1.908473e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>30.469500</td>\n",
       "      <td>8.838840</td>\n",
       "      <td>8.723130</td>\n",
       "      <td>8.707952</td>\n",
       "      <td>8.768843</td>\n",
       "      <td>204.950262</td>\n",
       "      <td>210.994656</td>\n",
       "      <td>-4.367419e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          V0000     V0001     V0002     V0003     V0004       V0005  \\\n",
       "1000  30.466746  8.766340  8.688246  8.725044  8.691887  164.129395   \n",
       "1000  30.461517  8.615086  8.707004  8.672025  8.726185  200.608939   \n",
       "1000  30.462584  8.734225  8.711064  8.700966  8.723912  180.847520   \n",
       "1000  30.486272  8.547549  8.705390  8.677280  8.684212  201.880368   \n",
       "1000  30.469500  8.838840  8.723130  8.707952  8.768843  204.950262   \n",
       "\n",
       "           V0006         V0007  V0008     V0009  ...  V5111  V5112  V5113  \\\n",
       "1000  192.704677  4.585456e-19    0.0  0.002620  ...    1.0    1.0    1.0   \n",
       "1000  180.603857  6.708315e-20    0.0  0.001803  ...    1.0    1.0    1.0   \n",
       "1000  170.057365  2.970597e-19    0.0 -0.001302  ...    1.0    1.0    1.0   \n",
       "1000  194.272476  1.908473e-19    0.0  0.000687  ...    1.0    1.0    1.0   \n",
       "1000  210.994656 -4.367419e-19    0.0  0.000318  ...    1.0    1.0    1.0   \n",
       "\n",
       "      V5114  V5115  V5116  V5117     V5118  V5119  V5120  \n",
       "1000    1.0   60.0    0.0    0.0 -0.000007   85.4    0.0  \n",
       "1000    1.0   60.0    0.0    0.0 -0.000002   85.4    0.0  \n",
       "1000    1.0   60.0    0.0    0.0 -0.000018   85.4    0.0  \n",
       "1000    1.0   60.0    0.0    0.0 -0.000018   85.4    0.0  \n",
       "1000    1.0   60.0    0.0    0.0  0.000013   85.4    0.0  \n",
       "\n",
       "[5 rows x 5121 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y 앞 5개\n",
      "\n",
      "0    110\n",
      "0    110\n",
      "0    110\n",
      "0    110\n",
      "0    110\n",
      "Name: label, dtype: int64\n",
      "\n",
      "y 뒤 5개\n",
      "\n",
      "99    156\n",
      "99    156\n",
      "99    156\n",
      "99    156\n",
      "99    156\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"y 앞 5개\\n\\n{}\".format(y.head(5)))\n",
    "print()\n",
    "print(\"y 뒤 5개\\n\\n{}\".format(y.tail(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델 학습, 검증, 저장\n",
    "### Model Tuning & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hyper Parameters of XGBoost](https://apple-rbox.tistory.com/6)<br>\n",
    "[Hyper Parameters of LightGBM 1](http://machinelearningkorea.com/2019/09/29/lightgbm-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0/)\n",
    "[Hyper Parameters of LightGBM 2](https://sites.google.com/view/lauraepp/parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = {\n",
    "    'learning_rate' : 0.06,     # default = 0.3, [0, 1] 학습률 : 낮을수록 보수적\n",
    "    'num_leaves' : 400,         # 최대 잎사귀 수 ex) depth = 4 -> (2의 4제곱 -1) = 15 \n",
    "    'n_estimators' : 300,       # default = 100, 1000개 정도 해도 좋고, 너무 크면 overfitting\n",
    "    'max_depth': -1,            # default = 6, [0, ∞] 나무깊이 : -1의 경우 제한이 없다. feature가 많다면 이렇게 설정.\n",
    "    \n",
    "    #    - child의 관측(?)에서 요구되는 최소 가중치의 합\n",
    "    #    - over-fitting vs under-fitting을 조정하기 위한 파라미터.\n",
    "    #    - 너무 큰 값이 주어지면 under-fitting.    \n",
    "    'min_child_weight' : 3,     #  min_child_weight [default=1] (Should be tuned using CV)\n",
    "    \n",
    "    # subsample : training데이터 셋에서 subset을 만들지 전부를 사용할지 정하는 파라미터, 매번 나무를 만들 때(=iteration) 적용하며 overfitting 문제를 방지하려고 사용.\n",
    "    'subsample' : 0.8,          # default = 1, (0, 1]\n",
    "    \n",
    "    'colsample_bytree' : 0.5,   # default = 1, (0,1] 나무 만들 때 변수를 샘플링할 지\n",
    "    'objective' : 'multiclass', # 이진분류할 지 다중분류할 지 등등\n",
    "    'n_jobs': -1                #\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM은 왜 이렇게 유명해졌나?\n",
    "[LGBM에 대한 설명](https://greatjoy.tistory.com/72)\n",
    "- 데이터의 크기가 커짐에 따라 빠른 결과를 내는 것도 중요해지고 있다. 그런점에서 Light GBM은 'Light'의 접두사와 같이 속도가 빠른 것이 장점이다. 메모리를 적게 차지하고 속도가 빠른다는 장점 외에도, LGBM은 결과의 정확도가 높다는 장점이 있다. 또한, GPU를 활용할 수 있기 때문에 널리 사용되고 있다. <br>\n",
    "- 하지만, 위에서 말했듯이 overfitting에 민감하여 데이터의 크기가 작을 경우 기존의 머신러닝 알고리즘이 더 좋을 수 있다. 경험저긍로 데이터의 개수(행 수)가 10,000개 이상일 때 추천한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.327013\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.306125\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.327785\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's multi_logloss: 0.307373\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.330042\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.306855\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.331275\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's multi_logloss: 0.309593\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.349587\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's multi_logloss: 0.327402\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.326719\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's multi_logloss: 0.304848\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.319266\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.296672\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.33043\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's multi_logloss: 0.308949\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.341623\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's multi_logloss: 0.320446\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.32503\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's multi_logloss: 0.303906\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.323643\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's multi_logloss: 0.301497\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-f74603276cb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         model.fit(x_train, y_train, eval_set=[(x_validation, y_validation)], early_stopping_rounds= 30,\n\u001b[1;32m---> 21\u001b[1;33m                   verbose=100) \n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;31m#joblib.dump(model, '../2_Code_pred/%s_fold_model_%s.pkl'%(n,rs))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'%s_fold_model_%s.pkl'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    803\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    806\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    598\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1976\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1978\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 4FOLD, 3SEED ENSEMBLE\n",
    "# 총 12개의 모델을 평균내어 예측한다\n",
    "\n",
    "lucky_seed=[4885,1992,1022]\n",
    "\n",
    "for num,rs in enumerate(lucky_seed):\n",
    "    \n",
    "    kfold = KFold(n_splits=4, random_state = rs, shuffle = True)\n",
    "\n",
    "    # dacon code\n",
    "    cv=np.zeros((train.shape[0],198))\n",
    "\n",
    "    for n, (train_idx, validation_idx) in enumerate(kfold.split(train)):\n",
    "        \n",
    "        x_train, x_validation = train.iloc[train_idx], train.iloc[validation_idx]\n",
    "        y_train, y_validation = y.iloc[train_idx], y.iloc[validation_idx]\n",
    "\n",
    "        model = lightgbm.LGBMClassifier(**parms, random_state=rs)\n",
    "\n",
    "        model.fit(x_train, y_train, eval_set=[(x_validation, y_validation)], early_stopping_rounds= 30,\n",
    "                  verbose=100) \n",
    "        #joblib.dump(model, '../2_Code_pred/%s_fold_model_%s.pkl'%(n,rs))\n",
    "        joblib.dump(model, path+'%s_fold_model_%s.pkl'%(n,rs))\n",
    "\n",
    "        # CROSS-VALIDATION , EVALUATE CV\n",
    "        cv[validation_idx,:] = model.predict_proba(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-d432e0541d8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mpredict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtemp_predictions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    861\u001b[0m         \"\"\"\n\u001b[0;32m    862\u001b[0m         result = super(LGBMClassifier, self).predict(X, raw_score, num_iteration,\n\u001b[1;32m--> 863\u001b[1;33m                                                      pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[0;32m    864\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_classes\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    663\u001b[0m                              % (self._n_features, n_features))\n\u001b[0;32m    664\u001b[0m         return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n\u001b[1;32m--> 665\u001b[1;33m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[0m\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[0;32m   2413\u001b[0m         return predictor.predict(data, num_iteration,\n\u001b[0;32m   2414\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2415\u001b[1;33m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[0;32m   2416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2417\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[1;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[0;32m    621\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__pred_for_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[1;34m(mat, num_iteration, predict_type, preds)\u001b[0m\n\u001b[0;32m    603\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m                 preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[0;32m    606\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wrong length for predict results\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MODEL LOAD & TEST PREDICT\n",
    "# 12 MODELS 평균 사용\n",
    "models = os.listdir(path)\n",
    "models_list = [x for x in models if x.endswith(\".pkl\")]\n",
    "assert len(models_list) ==11\n",
    "temp_predictions = np.zeros((test.shape[0],198))\n",
    "\n",
    "for m in models_list:\n",
    "    model = joblib.load(path+m)\n",
    "    predict_proba = model.predict_proba(test)\n",
    "    temp_predictions += predict_proba/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dacon code\n",
    "submission = pd.DataFrame(data=np.zeros((test.shape[0],198)))\n",
    "submission.index = test.index \n",
    "submission.index.name = 'id'\n",
    "submission+=temp_predictions\n",
    "\n",
    "submission = submission.sort_index()\n",
    "submission = submission.groupby('id').mean()\n",
    "submission.to_csv('submission.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 결과 및 결언\n",
    "## Conclusion & Discussion\n",
    "## 데이터 전처리\n",
    "PCA, Feature 정규화, Min-Max Scaling은 성능 향상에 도움이 되지 않음 Object와 NAN 값을 0으로 바꾸어 주는 전처리만 진행\n",
    "\n",
    "## 모델 학습 검증\n",
    "- Lgbm 모델 선택<br>\n",
    "Random Forest, Xgboost, LightGBM 모델 비교 결과 lgbm의 성능이 가장 좋았음<br>\n",
    "\n",
    "- K-fold & Random seed를 사용한 모델 하이퍼 파라미터 튜닝<br>\n",
    "Robust 한 모델을 만들기 위해 4Kfold * 3seed 총 12개의 모델을 만듬 Early stopping 값을 작게 설정하여 over-fitting 방지 min_child_weight 값을 CV를 통해 최적화 하여 over-fitting 방지 Soft-voting 예측 방법 선택<br>\n",
    "\n",
    "- Soft-voting 예측<br>\n",
    "예측 시 Hard-voting 방식과 Probability를 평균내는 Soft-voting 방식을 실험 evaluation metric이 log-loss였기 때문에 probability를 평균내는 방식의 성능이 좋았음 12개의 모델의 예측을 평균 하는 방식으로 최종 결과물 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system('shutdown -s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
